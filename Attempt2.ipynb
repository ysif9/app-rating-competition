{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading Data",
   "id": "3515bf599fe6b09a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "train_df_copy = pd.read_csv(\"cleaned_train_only_dropped_y.csv\")\n",
    "\n",
    "# Load test data (input features only)\n",
    "test_df = pd.read_csv(\"app-rating-competition/test.csv\")\n",
    "sample_submission = pd.read_csv(\"app-rating-competition/SampleSubmission.csv\")\n",
    "df_test_fr = pd.read_csv(\"extracted_test_rows_with_Y.csv\")\n"
   ],
   "id": "a049cb211665b0ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_df_copy",
   "id": "7333a1bd4edc404e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* Maybe try stratified sampling on review groups",
   "id": "e5f446371fd25b7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(train_df_copy, test_size=0.2, random_state=42)"
   ],
   "id": "93a42f1c6e4457c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_set.shape",
   "id": "70a8d5ea6a06016f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_set.shape",
   "id": "81f23cd1f762fd97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "|* For imputer try knn and iterative\n",
    "* Our missing data is MNAR"
   ],
   "id": "5cf77d142a10a6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pipeline",
   "id": "a80fcf465dbe73eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from preprocessing import *\n",
    "\n",
    "column_transform = ColumnTransformer(\n",
    "    [\n",
    "        (\"categories\", category_pipeline(), [\"app_category\", \"free_paid\"]),\n",
    "        (\"size\", box_cox_pipeline(), [\"size_unknown_unit\"]),\n",
    "        (\"downloads\", downloads_pipeline(), [\"downloads_unstandardized\"]),\n",
    "        (\"reviews\", reviews_pipeline(), [\"reviews_count\"]),\n",
    "        (\"price\", price_pipeline(), [\"price_if_paid\"]),\n",
    "        (\"age_rating\", age_rating_pipeline(), [\"age_rating\"]),\n",
    "        (\"dates\", release_date_pipeline(), [\"release_date\"]),\n",
    "        (\"os\", os_version_pipeline(), [\"compatible_os_version\"]),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")"
   ],
   "id": "3238d87948cc52cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "column_transform",
   "id": "3178122c50b11100"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* Currently there's still errors in mapping and numpy in the pipeline",
   "id": "74e9f4a4a447c513"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = train_set.copy()\n",
    "X_train = df.drop(columns=['Y'])\n",
    "y_train = df['Y']"
   ],
   "id": "602dd154df6fa9d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## XGB Model",
   "id": "4873690543a3b06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import scipy.stats as stats\n",
    "from joblib import Memory\n",
    "\n",
    "# ----- models -----\n",
    "xgb_final = XGBRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=2000,  # large ceiling\n",
    "    objective='reg:squarederror',\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "xgb_selector_base = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    random_state=42,\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "feature_selector = SelectFromModel(\n",
    "    estimator=xgb_selector_base,\n",
    "    threshold=\"median\"\n",
    ")\n",
    "\n",
    "xgb_model_transformed = TransformedTargetRegressor(\n",
    "    regressor=xgb_final,\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"preprocessing\", column_transform),\n",
    "    # (\"select\", feature_selector),\n",
    "    (\"regression\", xgb_model_transformed),\n",
    "])\n",
    "\n",
    "# ----- hyper‑param space -----\n",
    "param_dist = {\n",
    "    # # selector hyper‑params\n",
    "    # \"select__threshold\": [\"median\", \"1.5*mean\", 0.002, 0.01],\n",
    "    # \"select__estimator__max_depth\": stats.randint(3, 10),\n",
    "    # \"select__estimator__n_estimators\": stats.randint(50, 300),\n",
    "    # \"select__estimator__learning_rate\": stats.loguniform(0.03, 0.3),\n",
    "\n",
    "    # final XGB hyper‑params\n",
    "    'regression__regressor__max_depth': stats.randint(4, 9),\n",
    "    'regression__regressor__learning_rate': stats.loguniform(0.02, 0.15),\n",
    "    'regression__regressor__subsample': stats.uniform(0.6, 0.4),  # 0.6–1.0\n",
    "    'regression__regressor__colsample_bytree': stats.uniform(0.6, 0.4),\n",
    "    'regression__regressor__min_child_weight': stats.randint(1, 8),\n",
    "    'regression__regressor__gamma': stats.uniform(0, 2),\n",
    "    # lambdas rarely >2 are useful\n",
    "    'regression__regressor__reg_lambda': stats.loguniform(1e-2, 2),\n",
    "    # 'regression__regressor__early_stopping_rounds': [50],\n",
    "    'regression__regressor__eval_metric': ['rmse'],\n",
    "}\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=200,\n",
    "    cv=4,\n",
    "    scoring=mse_scorer,\n",
    "    n_jobs=8,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", random_search.best_params_)\n",
    "print(\"Best CV RMSE:\", -random_search.best_score_)\n",
    "# print(\"Selected features:\", random_search.best_estimator_\n",
    "#       .named_steps[\"select\"]\n",
    "#       .get_support()\n",
    "#       .sum())\n"
   ],
   "id": "54dd69c31ee6f2fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_test = test_set.copy()\n",
    "X_test = df_test.drop(columns=['Y'])\n",
    "y_test = df_test['Y']"
   ],
   "id": "6f33e00ad282d276"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_test_seet = df_test_fr.copy()\n",
    "X_test_set = df_test_seet.drop(columns=['Y'])\n",
    "y_test_set = df_test_seet['Y']"
   ],
   "id": "dfb5fb84621f6749"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "best_pipeline = random_search.best_estimator_\n",
    "\n",
    "# # Fit on training set\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_pipeline.predict(X_test_set)\n",
    "\n",
    "mse = mean_squared_error(y_test_set, y_pred)\n",
    "mae = mean_absolute_error(y_test_set, y_pred)\n",
    "r2 = r2_score(y_test_set, y_pred)\n",
    "\n",
    "# Output\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "print(f\"Test R²: {r2:.4f}\")\n",
    "# print(f\"Test RMSE: {rmse(y_test_set, y_pred):.4f}\")\n",
    "\n"
   ],
   "id": "2b6c5b8d45001028"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(\"Y variance:\", y_train.var())\n",
   "id": "c54fbb486a5f2960"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Error Analysis",
   "id": "7db94ba6910be251"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------\n",
    "# 0.  Setup ― run once\n",
    "# ------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "plt.style.use(\"default\")  # no seaborn → competition‑safe\n",
    "\n",
    "# y_true, y_pred, X_test must already exist\n",
    "residuals = y_test - y_pred\n",
    "abs_error = np.abs(residuals)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"RMSE = {rmse:.4f}   |   MAE = {mae:.4f}\")\n"
   ],
   "id": "ccb5a6dfc3591ad3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test, y_pred, s=8, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()],\n",
    "         ls=\"--\")\n",
    "plt.xlabel(\"True rating\")\n",
    "plt.ylabel(\"Predicted rating\")\n",
    "plt.title(\"Residual spread\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "380f3a216283580f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bins = pd.qcut(y_test, q=10, labels=False, duplicates=\"drop\")\n",
    "bin_rmse = (\n",
    "    pd.DataFrame({\"true\": y_test, \"pred\": y_pred, \"bin\": bins})\n",
    "    .groupby(\"bin\")\n",
    "    .apply(lambda df: np.sqrt(mean_squared_error(df[\"true\"], df[\"pred\"])))\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(bin_rmse.index.astype(str), bin_rmse.values)\n",
    "plt.xlabel(\"Y decile\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"RMSE across rating deciles\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "75ef5be6348ec8df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.hist(residuals, bins=20)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.show()\n"
   ],
   "id": "3d6304627eb79b7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# create Q-Q plot with 45-degree line added to plot\n",
    "fig = sm.qqplot(residuals, fit=True, line=\"45\", alpha=0.2)\n",
    "plt.show()"
   ],
   "id": "b1a870329e10ffb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cleanlab",
   "id": "db87c7fbed345ce8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## XGB Submission",
   "id": "87cea48543cae10d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_df",
   "id": "d03ef9dc42256c0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "# 2. Predict using trained pipeline\n",
    "y_pred_submission = best_pipeline.predict(test_df)\n",
    "\n",
    "# 4. Create final submission by replacing Y column\n",
    "sample_submission[\"Y\"] = y_pred_submission\n",
    "\n",
    "# 5. Save to CSV\n",
    "sample_submission.to_csv(\"one_try.csv\", index=False)\n",
    "\n",
    "print(\"✅ submission.csv created successfully with row_id and rounded Y.\")\n",
    "\n"
   ],
   "id": "9e34238b5e27f411"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LGB Model",
   "id": "daff8d1cdd352e57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def rename_columns(dataframe):\n",
    "    reformated_df = dataframe.rename(\n",
    "        columns={\"X0\": \"app_name\", \"X1\": \"app_category\", \"X2\": \"reviews_count\", \"X3\": \"size\",\n",
    "                 \"X4\": \"installs_count\", \"X5\": \"free_paid\", \"X6\": \"price_if_paid\", \"X7\": \"age_rating\",\n",
    "                 \"X8\": \"app_tags\", \"X9\": \"last_updated\", \"X10\": \"app_version\",\n",
    "                 \"X11\": \"compatible_os_version\"})\n",
    "    return reformated_df"
   ],
   "id": "6c24da85ff0cc627"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T17:42:27.012304Z",
     "start_time": "2025-05-10T17:42:26.943949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 1) Load your files\n",
    "#   - test.csv has the true Y column\n",
    "#   - preds.csv is the file you just created with row_id and Y\n",
    "test = pd.read_csv(\"extracted_test_rows_with_Y.csv\")\n",
    "preds = pd.read_csv(\"stacked_nlp_try2.csv\")  # or whatever your file is named\n",
    "\n",
    "# 2) Sanity‐check shapes\n",
    "assert len(test) == len(preds), f\"Length mismatch: test={len(test)} vs preds={len(preds)}\"\n",
    "\n",
    "# 3) Extract true & predicted arrays (ignore row_id)\n",
    "y_true = test[\"Y\"].values\n",
    "y_pred = preds[\"Y\"].values\n",
    "\n",
    "# 4) Compute metrics\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"MSE : {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE : {mae:.4f}\")\n",
    "print(f\"R²  : {r2:.4f}\")\n"
   ],
   "id": "3b2906cab6b9820",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.1892\n",
      "RMSE: 0.4350\n",
      "MAE : 0.2941\n",
      "R²  : 0.2328\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "import scipy.stats as stats\n",
    "import optuna\n",
    "\n",
    "# 1) Split off a local hold‐out if you don’t already have one\n",
    "X_full = train_df_copy.drop(columns=[\"Y\"])\n",
    "y_full = train_df_copy[\"Y\"]\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_full, y_full, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 2) Build the pipeline\n",
    "lgb = LGBMRegressor(\n",
    "    objective=\"regression\",\n",
    "    # device=\"gpu\",\n",
    "    random_state=42,\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "# lgb_model_transformed = TransformedTargetRegressor(\n",
    "#     regressor=lgb,\n",
    "#     func=np.log1p,\n",
    "#     inverse_func=np.expm1\n",
    "# )\n",
    "\n",
    "pipe_lgb = Pipeline([\n",
    "    (\"preprocessing\", column_transform),\n",
    "    (\"reg\", lgb)\n",
    "])\n",
    "\n",
    "# 3) Hyperparameter space\n",
    "param_dist_lgb = {\n",
    "    \"reg__regressor__n_estimators\": stats.randint(200, 1000),\n",
    "    \"reg__regressor__learning_rate\": stats.loguniform(0.01, 0.2),\n",
    "    \"reg__regressor__num_leaves\": stats.randint(20, 256),\n",
    "    \"reg__regressor__min_child_samples\": stats.randint(5, 100),\n",
    "    \"reg__regressor__subsample\": stats.uniform(0.6, 0.4),\n",
    "    \"reg__regressor__colsample_bytree\": stats.uniform(0.6, 0.4),\n",
    "    \"reg__regressor__reg_alpha\": stats.loguniform(1e-4, 1),\n",
    "    \"reg__regressor__reg_lambda\": stats.loguniform(1e-4, 1),\n",
    "}\n",
    "\n",
    "\n",
    "# 4) RMSE scorer\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "\n",
    "# lgb_search.fit(X_tr, y_tr)\n",
    "# 5) Randomized search\n",
    "lgb_search = RandomizedSearchCV(\n",
    "    pipe_lgb,\n",
    "    param_distributions=param_dist_lgb,\n",
    "    n_iter=100,\n",
    "    cv=5,\n",
    "    scoring=mse_scorer,\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "lgb_search.fit(X_tr, y_tr)\n",
    "\n",
    "print(\"Best LGB params:\", lgb_search.best_params_)\n",
    "print(\"Best CV RMSE  :\", -lgb_search.best_score_)\n",
    "\n",
    "# 6) Evaluate on hold-out\n",
    "best_lgb = lgb_search.best_estimator_\n",
    "y_pred = best_lgb.predict(X_val)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "rm = np.sqrt(mse)\n",
    "\n",
    "print(f\"Hold-out MSE : {mse:.4f}\")\n",
    "print(f\"Hold-out RMSE: {rm:.4f}\")\n",
    "print(f\"Hold-out MAE : {mae:.4f}\")\n",
    "print(f\"Hold-out R²  : {r2:.4f}\")\n"
   ],
   "id": "9aa4409da33c0f74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_pred = best_lgb.predict(X_test_set)\n",
    "\n",
    "mse = mean_squared_error(y_test_set, y_pred)\n",
    "mae = mean_absolute_error(y_test_set, y_pred)\n",
    "r2 = r2_score(y_test_set, y_pred)\n",
    "rm = np.sqrt(mse)\n",
    "\n",
    "print(f\"Hold-out MSE : {mse:.4f}\")\n",
    "print(f\"Hold-out RMSE: {rm:.4f}\")\n",
    "print(f\"Hold-out MAE : {mae:.4f}\")\n",
    "print(f\"Hold-out R²  : {r2:.4f}\")"
   ],
   "id": "4836e03208205755"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "# 2. Predict using trained pipeline\n",
    "y_pred_submission = best_lgb.predict(test_df)\n",
    "\n",
    "# 4. Create final submission by replacing Y column\n",
    "sample_submission[\"Y\"] = y_pred_submission\n",
    "\n",
    "# 5. Save to CSV\n",
    "sample_submission.to_csv(\"lgb_try.csv\", index=False)\n",
    "\n",
    "print(\"✅ submission.csv created successfully with row_id and rounded Y.\")\n",
    "\n"
   ],
   "id": "60063b3602b18c25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge, ElasticNetCV\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# 1) Define base learners\n",
    "estimators = [\n",
    "    (\"lgb\", lgb_search.best_estimator_),\n",
    "    (\"xgb\", random_search.best_estimator_),\n",
    "    # (\"cat\", CatBoostRegressor(\n",
    "    #             loss_function=\"RMSE\",\n",
    "    #             iterations=800,\n",
    "    #             learning_rate=0.05,\n",
    "    #             depth=6,\n",
    "    #             random_state=42,\n",
    "    #             verbose=0)),\n",
    "    (\"lin\", Pipeline([\n",
    "                (\"pre\",   column_transform),\n",
    "                (\"scale\", StandardScaler(with_mean=False)),\n",
    "                (\"reg\",   ElasticNetCV(\n",
    "                              alphas=np.logspace(-4,1,30),\n",
    "                              l1_ratio=[.1,.5,.9,1],\n",
    "                              cv=5,\n",
    "                              n_jobs=-1))\n",
    "    ]))\n",
    "]\n",
    "\n",
    "# 2) Meta-learner grid\n",
    "meta = RidgeCV(alphas=np.logspace(-4, 1, 20), cv=5)\n",
    "\n",
    "# 3) Stacking regressor\n",
    "stack = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=meta,\n",
    "    passthrough=True,\n",
    "    cv=RepeatedKFold(n_splits=5, n_repeats=2, random_state=42),\n",
    "    n_jobs=8\n",
    ")\n",
    "\n",
    "# 4) Fit & evaluate\n",
    "X_full = train_df_copy.drop(columns=[\"Y\"])\n",
    "y_full = train_df_copy[\"Y\"]\n",
    "stack.fit(X_full, y_full)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    stack,\n",
    "    X_full,\n",
    "    y_full,\n",
    "    cv=RepeatedKFold(n_splits=5, n_repeats=2, random_state=42),\n",
    "    scoring=make_scorer(lambda y,t: np.sqrt(mean_squared_error(y,t)), greater_is_better=False),\n",
    "    n_jobs=8\n",
    ")\n",
    "print(f\"Improved Stack RMSE: {-cv_scores.mean():.4f}\")\n"
   ],
   "id": "c9ef4de2d265c559"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_pred = stack.predict(X_test_set)\n",
    "\n",
    "mse = mean_squared_error(y_test_set, y_pred)\n",
    "mae = mean_absolute_error(y_test_set, y_pred)\n",
    "r2 = r2_score(y_test_set, y_pred)\n",
    "rm = np.sqrt(mse)\n",
    "\n",
    "print(f\"Hold-out MSE : {mse:.4f}\")\n",
    "print(f\"Hold-out RMSE: {rm:.4f}\")\n",
    "print(f\"Hold-out MAE : {mae:.4f}\")\n",
    "print(f\"Hold-out R²  : {r2:.4f}\")"
   ],
   "id": "20f1fec088338a71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "773fdbafdc4a5b7c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
